{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outer-vulnerability",
   "metadata": {},
   "source": [
    "### In this notebook we hava created a scraping tool for tripadvisor. This notebooks is an addition to the review scarping tool to gain additional information about restaurants and reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "induced-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import string\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "leading-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEt all the reviwer info, location, join date, review count, upvotes, followers and following.\n",
    "def reviewerInfo(url):\n",
    "    username = url\n",
    "    full_url = f\"https://www.tripadvisor.com/Profile/{url}\"\n",
    "    driver.get(full_url)\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Get Intro info, location and join date\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    try:\n",
    "        location = soup.find('span', class_ = \"_2VknwlEe _3J15flPT default\").text\n",
    "    except:\n",
    "        location = None\n",
    "\n",
    "    try:\n",
    "        joined = soup.find('span', class_ = \"_1CdMKu4t\").text\n",
    "    except:\n",
    "        joined = None\n",
    "\n",
    "\n",
    "    all_links = soup.find_all('div', class_ = '_1aVEDY08')\n",
    "    # link = driver.find_elements_by_xpath(\"//div[@class='nkw-3XeH']/div[1]/span[2]/a\")\n",
    "\n",
    "    # # Get the contributions info\n",
    "    nrContributions = int(str(all_links[0].text).split()[1])\n",
    "    if nrContributions > 0:\n",
    "        link = driver.find_elements_by_xpath(\"//div[@class='nkw-3XeH']/div[1]/span[2]/a\")\n",
    "        driver.execute_script(\"arguments[0].click();\", link[0])\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        nrReviews = int(str(soup.find('span', class_ = 'ui_icon pencil-paper _1LSVmZLi').parent.text).split()[0])\n",
    "        try:\n",
    "            nrUpvotes = int(str(soup.find('span', class_ ='ui_icon thumbs-up _1LSVmZLi _3zmXi7gU').parent.text).split()[0])\n",
    "        except:\n",
    "            nrUpvotes = 0\n",
    "        close = driver.find_elements_by_xpath(\"//div[@class='_2EFRp_bb _9Wi4Mpeb']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", close[0])\n",
    "    else:\n",
    "        nrReviews = 0\n",
    "        nrUpvotes = 0\n",
    "\n",
    "    # Get Followers\n",
    "    nrFollowers = int(str(all_links[1].text).split()[1])\n",
    "    if nrFollowers > 0:\n",
    "        link = driver.find_elements_by_xpath(\"//div[@class='nkw-3XeH']/div[2]/span[2]/a\")\n",
    "        driver.execute_script(\"arguments[0].click();\", link[0])\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        followers = [word.text for word in soup.find('div', class_='_1caczhWN').find_all('span', class_='gf69u3Nd')]\n",
    "        close = driver.find_elements_by_xpath(\"//div[@class='_2EFRp_bb _9Wi4Mpeb']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", close[0])\n",
    "    else:\n",
    "        followers = []\n",
    "\n",
    "    # Get all following\n",
    "    nrFollowing = int(str(all_links[2].text).split()[1])\n",
    "    if nrFollowing > 0:\n",
    "        link = driver.find_elements_by_xpath(\"//div[@class='nkw-3XeH']/div[3]/span[2]/a\")\n",
    "        driver.execute_script(\"arguments[0].click();\", link[0])\n",
    "        time.sleep(1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        following = [word.text for word in soup.find('div', class_='_1caczhWN').find_all('span', class_='gf69u3Nd')]\n",
    "        close = driver.find_elements_by_xpath(\"//div[@class='_2EFRp_bb _9Wi4Mpeb']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", close[0])\n",
    "    else:\n",
    "        following = []\n",
    "\n",
    "    with open(pathtoReviewers, mode='a', encoding=\"utf-8\") as reviewer_data:\n",
    "        data_writer = csv.writer(reviewer_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "        data_writer.writerow([username, location, joined, nrContributions,nrReviews, nrUpvotes, nrFollowers, followers, nrFollowing,following])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "positive-norwegian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtoReviewers = \"reviewerInfo_kristin.csv\"\n",
    "with open(pathtoReviewers, mode='a', encoding=\"utf-8\") as reviewer_data:\n",
    "    data_writer = csv.writer(reviewer_data, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "    data_writer.writerow(['username', 'location', 'joined', 'nrContributions','nrReviews', 'nrUpvotes', 'nrFollowers','followers', 'nrFollowing','following'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = f'{os.getcwd()}/chromedriver'\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "\n",
    "with open(\"all_reviewers.txt\", \"rb\") as f:   # Unpickling\n",
    "    reviewers = pickle.load(f)\n",
    "\n",
    "reviewer_slice = reviewers[0:25000]\n",
    "bad_url = []\n",
    "i = 0\n",
    "for reviewer in reviewer_slice:\n",
    "    try:\n",
    "        reviewerInfo(reviewer)\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        i+=1\n",
    "    except:\n",
    "        bad_url.append(reviewer)\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
